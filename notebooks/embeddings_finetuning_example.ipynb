{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Install the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets peft"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Generate data for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How does a basic game of Dungeons & Dragons progress with respect to the roles of the Dungeon Master and the players?',\n",
       " \"In a tabletop role-playing game, what is the process that the game master follows when a player's action results in a challenging situation?\",\n",
       " 'How does the nature of gameplay in a tabletop role-playing game like Dungeons & Dragons typically vary with the circumstances?',\n",
       " 'What methods can a Dungeon Master use to help set the scene in a tabletop role-playing game, and how do players also contribute to character portrayal?',\n",
       " 'In the game Dungeons & Dragons, how is the result of a roll of percentile dice, or d100, generated and read, particularly when the ten-sided dice are numbered in tens?',\n",
       " 'How can one simulate a roll of 1d3 or 1d2 in a tabletop role-playing game using a d6 or any die?',\n",
       " 'In the gameplay of Dungeons & Dragons, how is the success or failure of an action determined?',\n",
       " 'What are the steps involved in making a d20 roll in a tabletop role-playing game?',\n",
       " 'In a tabletop role-playing game, how is success or failure determined when an action is taken?',\n",
       " \"In a tabletop role-playing game, how is a roll affected by the terms 'advantage' and 'disadvantage'?\",\n",
       " 'What are the characteristics of a successful party of adventurers in a Dungeons & Dragons game?',\n",
       " 'In a tabletop role-playing game like Dungeons & Dragons, who might be responsible for creating an adventure and what elements does that adventure typically feature?',\n",
       " 'What types of interactions could player characters have in a tabletop role-playing game?',\n",
       " 'How can the structure of adventures and campaigns in a tabletop role-playing game be compared to the structure of a TV series?',\n",
       " 'In a tabletop role-playing game like Dungeons & Dragons, how is exploration carried out?',\n",
       " 'What are some of the key features of gameplay and character interaction in a role-playing game like Dungeons & Dragons?',\n",
       " 'What is the most structured element of a D&D session and what possible actions can players undertake during this part?',\n",
       " 'In the context of the game Dungeons & Dragons, how often does magic occur and how is it viewed by the common folk?',\n",
       " 'In a role-playing game like Dungeons & Dragons, why is magic considered crucial for adventurers and what are the various ways it can be used?',\n",
       " 'What are the elements involved in creating a character in a tabletop role-playing game like Dungeons & Dragons?',\n",
       " 'What considerations should a player take into account when creating a character for Dungeons & Dragons?',\n",
       " \"What is the process of character creation in tabletop roleplaying games like Dungeons & Dragons, and how can one track their character's development?\",\n",
       " 'How do the racial traits of lightfoot halflings and high elves influence their suitability for certain classes in Dungeons & Dragons?',\n",
       " 'What aspects are considered when creating a character in a tabletop role-playing game like Dungeons & Dragons?',\n",
       " 'What are some of the benefits a character gets from their chosen class in a game of Dungeons & Dragons?',\n",
       " 'What signifies the entry of a character into the adventuring life in Dungeons & Dragons and what is the relevance of experience points?',\n",
       " 'In the game Dungeons & Dragons, how is the toughness of a character determined, and what role does the class of a character play in this?',\n",
       " \"In a game of Dungeons & Dragons, what aspects does a 1st-level character's proficiency bonus of +2 apply to, and how are hit points recorded and regained?\",\n",
       " \"In role-playing games like Dungeons & Dragons, what are the determinants of a character's proficiency in skills, tools, and saving throws, and are there any restrictions on the addition of the proficiency bonus?\",\n",
       " 'What are the six abilities that are considered when creating a character class in a game like Dungeons & Dragons and how does each ability affect the game play?',\n",
       " 'How are ability scores generated and assigned in a game of Dungeons & Dragons, and how are the ability modifiers determined?',\n",
       " \"How are a character's initial hit points calculated in the Dungeons & Dragons role-playing game based on a character called Bruenor?\",\n",
       " \"What is the range of ability scores a player can have before applying racial increases when customizing their character's abilities in Dungeons & Dragons, using the variant rule, and how can this enhance flexibility in score distribution?\",\n",
       " 'What elements are considered when fleshing out a character for a role-playing game?',\n",
       " \"In the process of character creation in a role-playing game like Dungeons & Dragons, how do a character's abilities and race influence their appearance and personality, and what benefits does a character's background provide?\",\n",
       " 'What physical and mental characteristics might be associated with a high Wisdom score in a tabletop role-playing game character?',\n",
       " \"What are the implications on a character's personality and backstory in a tabletop role-playing game if he has high Strength and Constitution, low Intelligence, and comes from a noble line?\",\n",
       " 'In the context of tabletop role-playing games like Dungeons & Dragons, what kind of personality traits and ideals might a dwarf character with a folk hero background possess?',\n",
       " \"In Dungeons & Dragons, what influences a character's starting equipment and what limits does a character's strength score impose?\",\n",
       " \"In the role-playing game Dungeons & Dragons, how is a character's Armor Class calculated in the absence of armor or a shield, and what are the implications of wearing armor or carrying a shield without the required proficiency?\",\n",
       " \"How do you determine which modifier to use when attacking with a melee weapon in a tabletop role-playing game, and how does the weapon's property, like finesse, affect this?\",\n",
       " 'In a role-playing game, if a player character, Bruenor, uses a battleaxe as his weapon, how is his attack bonus and damage calculated?']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "file_path = '../data/full_test/questions.json'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "questions = [data[q]['question']['question'] for q in range(len(data))]\n",
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.chat_models import AzureChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureChatOpenAI(\n",
    "    openai_api_key=os.getenv('OPENAI_API_KEY'),\n",
    "    azure_endpoint=os.getenv('AZURE_ENDPOINT'),\n",
    "    openai_api_version='2023-08-01-preview',\n",
    "    deployment_name='gpt4_1106-Preview',\n",
    "    temperature=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from synthlume.pipeline.step.text_generation_step import QuestionNewStyleStep\n",
    "\n",
    "question_new_style_step = QuestionNewStyleStep(llm=llm, language='en')\n",
    "\n",
    "generated_questions = []\n",
    "for i in range(len(questions)):\n",
    "    questions_dict = {'question': questions[i], 'new_style': 'informal'}\n",
    "    generated_question = question_new_style_step.generate(**questions_dict)\n",
    "    generated_questions.append(generated_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>style</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How does a basic game of Dungeons &amp; Dragons pr...</td>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In a tabletop role-playing game, what is the p...</td>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How does the nature of gameplay in a tabletop ...</td>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What methods can a Dungeon Master use to help ...</td>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>In the game Dungeons &amp; Dragons, how is the res...</td>\n",
       "      <td>original</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Hey, so if you're rolling up a dwarf character...</td>\n",
       "      <td>informal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Hey, so in D&amp;D, what stuff decides what gear y...</td>\n",
       "      <td>informal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Hey, so in D&amp;D, how do you figure out a charac...</td>\n",
       "      <td>informal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Hey, so when you're swinging a sword or someth...</td>\n",
       "      <td>informal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Hey, so when Bruenor swings his battleaxe arou...</td>\n",
       "      <td>informal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             question     style  label\n",
       "0   How does a basic game of Dungeons & Dragons pr...  original      1\n",
       "1   In a tabletop role-playing game, what is the p...  original      1\n",
       "2   How does the nature of gameplay in a tabletop ...  original      1\n",
       "3   What methods can a Dungeon Master use to help ...  original      1\n",
       "4   In the game Dungeons & Dragons, how is the res...  original      1\n",
       "..                                                ...       ...    ...\n",
       "79  Hey, so if you're rolling up a dwarf character...  informal      0\n",
       "80  Hey, so in D&D, what stuff decides what gear y...  informal      0\n",
       "81  Hey, so in D&D, how do you figure out a charac...  informal      0\n",
       "82  Hey, so when you're swinging a sword or someth...  informal      0\n",
       "83  Hey, so when Bruenor swings his battleaxe arou...  informal      0\n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "original_df = pd.DataFrame({'question': questions, 'style': 'original'})\n",
    "\n",
    "generated_df = pd.DataFrame(generated_questions)\n",
    "generated_df['style'] = generated_df['new_style']\n",
    "generated_df.drop('new_style', axis=1, inplace=True)\n",
    "\n",
    "df = pd.concat([original_df, generated_df], ignore_index=True)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['style'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 71 samples\n",
      "Validation data: 13 samples\n"
     ]
    }
   ],
   "source": [
    "# split df into train and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, val_df = train_test_split(df, test_size=0.15, random_state=369, stratify=df['label'])\n",
    "\n",
    "print(f'Train data: {len(train_df)} samples')\n",
    "print(f'Validation data: {len(val_df)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../data/embeddings_finetune_data_train.csv', index=False)\n",
    "val_df.to_csv('../data/embeddings_finetune_data_val.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Prepare data for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "\n",
    "train_examples = []\n",
    "val_examples = []\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "  example = train_dataset[i]\n",
    "  train_examples.append(InputExample(texts=[example['question']], label=example['label']))\n",
    "\n",
    "for i in range(len(val_dataset)):\n",
    "  example = val_dataset[i]\n",
    "  val_examples.append(InputExample(texts=[example['question']], label=example['label']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Prepare the model for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model_id = 'sentence-transformers/all-MiniLM-L6-v2'\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False})\n",
       "  (2): Normalize()\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41161135"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_1 = model.encode(questions[0], normalize_embeddings=True)\n",
    "embeddings_2 = model.encode(generated_questions[0]['question'], normalize_embeddings=True)\n",
    "\n",
    "# compute cosine similarity as dot product of normalized embeddings\n",
    "import numpy as np\n",
    "np.dot(embeddings_1, embeddings_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 384)\n",
       "    (token_type_embeddings): Embedding(2, 384)\n",
       "    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-5): 6 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model = list(model[0].children())[0]\n",
    "encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 22713216\n"
     ]
    }
   ],
   "source": [
    "print('Trainable parameters:', sum(p.numel() for p in encoder_model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import get_peft_model, LoraConfig, TaskType\n",
    "\n",
    "lora_target_modules = [f'encoder.layer.{n}.attention.self.query' for n in range(6)]\n",
    "lora_target_modules = lora_target_modules + [f'encoder.layer.{n}.attention.self.key' for n in range(6)]\n",
    "lora_target_modules = lora_target_modules + [f'encoder.layer.{n}.attention.self.value' for n in range(6)]\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "task_type=TaskType.FEATURE_EXTRACTION, inference_mode=False, r=16, lora_alpha=16, lora_dropout=0.1, bias='all', target_modules=lora_target_modules\n",
    ")\n",
    "\n",
    "encoder_model = get_peft_model(encoder_model, peft_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForFeatureExtraction(\n",
       "  (base_model): LoraModel(\n",
       "    (model): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 384, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 384)\n",
       "        (token_type_embeddings): Embedding(2, 384)\n",
       "        (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-5): 6 x BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=384, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (key): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=384, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (value): lora.Linear(\n",
       "                  (base_layer): Linear(in_features=384, out_features=384, bias=True)\n",
       "                  (lora_dropout): ModuleDict(\n",
       "                    (default): Dropout(p=0.1, inplace=False)\n",
       "                  )\n",
       "                  (lora_A): ModuleDict(\n",
       "                    (default): Linear(in_features=384, out_features=16, bias=False)\n",
       "                  )\n",
       "                  (lora_B): ModuleDict(\n",
       "                    (default): Linear(in_features=16, out_features=384, bias=False)\n",
       "                  )\n",
       "                  (lora_embedding_A): ParameterDict()\n",
       "                  (lora_embedding_B): ParameterDict()\n",
       "                )\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 247296\n"
     ]
    }
   ],
   "source": [
    "print('Trainable parameters:', sum(p.numel() for p in encoder_model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the loss function takes care of mining the triplets (an anchor sentence paired with a positive sentence and paired with a negative sentence), according to the label they belong, the builtin evaluator functions to be used during training, such as the [`BinaryEmbeddingSimilarityEvaluator`](https://github.com/UKPLab/sentence-transformers/blob/master/sentence_transformers/evaluation/BinaryClassificationEvaluator.py) need to have sentence pairs prepared beforehand with labels being 0 for dissimilar pairs and 1 for similar pairs.\n",
    "\n",
    "The function below is used to create such pairs from the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def create_question_pairs(df, samples_per_category):\n",
    "    # Create an empty dataframe with the required columns\n",
    "    result = pd.DataFrame(columns=['question1', 'question2', 'label'])\n",
    "  \n",
    "    # Sample data from each category\n",
    "    sampled_data = {}\n",
    "    for category, num_samples in samples_per_category.items():\n",
    "        sampled_data[category] = df[df['style'] == category].sample(n=num_samples)\n",
    "  \n",
    "    label_counts = {0: 0, 1: 0}\n",
    "    rows_to_add = []  # A list to collect rows before concatenating\n",
    "  \n",
    "    # Generate all possible combinations of sampled data\n",
    "    for category1, category2 in itertools.combinations(samples_per_category.keys(), 2):\n",
    "        # Within-category combinations\n",
    "        for i, j in itertools.combinations(sampled_data[category1].index, 2):\n",
    "            if i < j:\n",
    "                question1 = df.loc[i, 'question']\n",
    "                question2 = df.loc[j, 'question']\n",
    "            else:\n",
    "                question1 = df.loc[j, 'question']\n",
    "                question2 = df.loc[i, 'question']\n",
    "              \n",
    "            # Check for duplicates before adding to the result\n",
    "            if not ((result['question1'] == question1) & (result['question2'] == question2)).any():\n",
    "                rows_to_add.append({'question1': question1, 'question2': question2, 'label': 1})\n",
    "                label_counts[1] += 1\n",
    "  \n",
    "        # Between-category combinations\n",
    "        for i, j in itertools.product(sampled_data[category1].index, sampled_data[category2].index):\n",
    "            if i < j:\n",
    "                question1 = df.loc[i, 'question']\n",
    "                question2 = df.loc[j, 'question']\n",
    "            else:\n",
    "                question1 = df.loc[j, 'question']\n",
    "                question2 = df.loc[i, 'question']\n",
    "  \n",
    "            # Check for duplicates before adding to the result\n",
    "            if not ((result['question1'] == question1) & (result['question2'] == question2)).any():\n",
    "                rows_to_add.append({'question1': question1, 'question2': question2, 'label': 0})\n",
    "                label_counts[0] += 1\n",
    "  \n",
    "    # Use pd.concat to add all the rows at once\n",
    "    if rows_to_add:\n",
    "        result = pd.concat([result, pd.DataFrame(rows_to_add)], ignore_index=True)\n",
    "  \n",
    "    # Trim the output to have an equal number of pairs for each label\n",
    "    min_label_count = min(label_counts.values())\n",
    "    trimmed_result = pd.DataFrame()\n",
    "    for label in [0, 1]:\n",
    "        trimmed_result = pd.concat([trimmed_result, result[result['label'] == label].sample(n=min_label_count)], ignore_index=True)\n",
    "  \n",
    "    return trimmed_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "style\n",
       "original    7\n",
       "informal    6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df['style'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In the game Dungeons &amp; Dragons, how is the tou...</td>\n",
       "      <td>Hey, so like, what cool perks do you snag when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In the context of the game Dungeons &amp; Dragons,...</td>\n",
       "      <td>Hey, so like, what cool perks do you snag when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What signifies the entry of a character into t...</td>\n",
       "      <td>Hey, so like, what cool perks do you snag when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How can one simulate a roll of 1d3 or 1d2 in a...</td>\n",
       "      <td>Hey, so like, what cool perks do you snag when...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How can one simulate a roll of 1d3 or 1d2 in a...</td>\n",
       "      <td>Hey, so when you're rolling up a character in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What signifies the entry of a character into t...</td>\n",
       "      <td>Hey, so when you're rolling up a character in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>In the context of the game Dungeons &amp; Dragons,...</td>\n",
       "      <td>In the game Dungeons &amp; Dragons, how is the tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can one simulate a roll of 1d3 or 1d2 in a...</td>\n",
       "      <td>In the game Dungeons &amp; Dragons, how is the tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In the context of the game Dungeons &amp; Dragons,...</td>\n",
       "      <td>What signifies the entry of a character into t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What signifies the entry of a character into t...</td>\n",
       "      <td>In the game Dungeons &amp; Dragons, how is the tou...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>How can one simulate a roll of 1d3 or 1d2 in a...</td>\n",
       "      <td>What signifies the entry of a character into t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>How can one simulate a roll of 1d3 or 1d2 in a...</td>\n",
       "      <td>In the context of the game Dungeons &amp; Dragons,...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question1  \\\n",
       "0   In the game Dungeons & Dragons, how is the tou...   \n",
       "1   In the context of the game Dungeons & Dragons,...   \n",
       "2   What signifies the entry of a character into t...   \n",
       "3   How can one simulate a roll of 1d3 or 1d2 in a...   \n",
       "4   How can one simulate a roll of 1d3 or 1d2 in a...   \n",
       "5   What signifies the entry of a character into t...   \n",
       "6   In the context of the game Dungeons & Dragons,...   \n",
       "7   How can one simulate a roll of 1d3 or 1d2 in a...   \n",
       "8   In the context of the game Dungeons & Dragons,...   \n",
       "9   What signifies the entry of a character into t...   \n",
       "10  How can one simulate a roll of 1d3 or 1d2 in a...   \n",
       "11  How can one simulate a roll of 1d3 or 1d2 in a...   \n",
       "\n",
       "                                            question2 label  \n",
       "0   Hey, so like, what cool perks do you snag when...     0  \n",
       "1   Hey, so like, what cool perks do you snag when...     0  \n",
       "2   Hey, so like, what cool perks do you snag when...     0  \n",
       "3   Hey, so like, what cool perks do you snag when...     0  \n",
       "4   Hey, so when you're rolling up a character in ...     0  \n",
       "5   Hey, so when you're rolling up a character in ...     0  \n",
       "6   In the game Dungeons & Dragons, how is the tou...     1  \n",
       "7   In the game Dungeons & Dragons, how is the tou...     1  \n",
       "8   What signifies the entry of a character into t...     1  \n",
       "9   In the game Dungeons & Dragons, how is the tou...     1  \n",
       "10  What signifies the entry of a character into t...     1  \n",
       "11  In the context of the game Dungeons & Dragons,...     1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df_pairs = create_question_pairs(val_df, {'original': 4, 'informal': 4})\n",
    "val_df_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of directly using the `BinaryClassificationEvaluator`, here we show how to create a custom evaluator derived from it but implementing a custom evaluation metric.\n",
    "\n",
    "We call this metric separation score. It computes a value such that the closer this value to 1, the better separated are the sentences of different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.evaluation import BinaryClassificationEvaluator\n",
    "from sklearn.metrics.pairwise import paired_cosine_distances\n",
    "from typing import List\n",
    "\n",
    "class CustomBinaryClassificationEvaluator(BinaryClassificationEvaluator):  \n",
    "    def __init__(  \n",
    "        self,  \n",
    "        questions1: List[str],  \n",
    "        questions2: List[str],  \n",
    "        labels: List[int],  \n",
    "        name: str = \"\",  \n",
    "        show_progress_bar: bool = False,  \n",
    "        batch_size: int = 512,  \n",
    "        write_csv: bool = False,\n",
    "        \n",
    "        num_steps: int = 0,\n",
    "    ):  \n",
    "        super().__init__(questions1, questions2, labels, name, show_progress_bar, batch_size, write_csv)\n",
    "\n",
    "        self.questions1 = questions1\n",
    "        self.questions2 = questions2\n",
    "        self.labels = labels\n",
    "        self.num_steps = num_steps\n",
    "  \n",
    "    def __call__(self, model: SentenceTransformer, output_path: str = None, epoch: int = -1, steps: int = -1) -> float:\n",
    "        \n",
    "        # First, compute the sentence embeddings using the model  \n",
    "        questions = list(set(self.questions1 + self.questions2))\n",
    "        embeddings = model.encode(questions, batch_size=self.batch_size, convert_to_numpy=True, normalize_embeddings=True)\n",
    "        emb_dict = {question: emb for question, emb in zip(questions, embeddings)}\n",
    "        embeddings1 = [emb_dict[question] for question in self.questions1]\n",
    "        embeddings2 = [emb_dict[question] for question in self.questions2]\n",
    "\n",
    "        # Next, compute the cosine similarity between the embeddings\n",
    "        dist_scores = paired_cosine_distances(embeddings1, embeddings2)\n",
    "        \n",
    "        # Cmpute the average similarity score for similar and non-similar pairs\n",
    "        labels = np.asarray(self.labels)\n",
    "        positive_pairs = labels == 1\n",
    "        positive_pairs_dist_scores = dist_scores[positive_pairs]\n",
    "        negative_pairs = labels == 0\n",
    "        negative_pairs_dist_scores = dist_scores[negative_pairs]\n",
    "\n",
    "        # Compute the average distance between similar pairs and non-similar pairs\n",
    "        mean_positive_dist_score = np.mean(positive_pairs_dist_scores)\n",
    "        mean_negative_dist_score = np.mean(negative_pairs_dist_scores)\n",
    "\n",
    "        # Compute a normalized separation score such that the closer the value to 1, the better separated are the sentences of different categories \n",
    "        separation_score = ((1 - mean_positive_dist_score) + mean_negative_dist_score) / 2\n",
    "\n",
    "        if steps == self.num_steps:\n",
    "            print(f\"epoch: {epoch}\")\n",
    "            print(f\"Separation score: {separation_score:.4f}\")\n",
    "            print(f\"Average distance between similar pairs: {mean_positive_dist_score:.4f}\")\n",
    "            print(f\"Average distance between non-similar pairs: {mean_negative_dist_score:.4f}\")\n",
    "\n",
    "        return separation_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n",
    "val_dataloader = DataLoader(val_examples, shuffle=False, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers.losses import BatchSemiHardTripletLoss\n",
    "\n",
    "train_loss = BatchSemiHardTripletLoss(model=model)\n",
    "\n",
    "num_epochs = 15\n",
    "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions1 = val_df_pairs['question1'].tolist()\n",
    "questions2 = val_df_pairs['question2'].tolist()\n",
    "labels = val_df_pairs['label'].tolist()\n",
    "\n",
    "evaluator = CustomBinaryClassificationEvaluator(questions1=questions1, questions2=questions2, labels=labels, batch_size=16, show_progress_bar=True,\n",
    "                                                num_steps=len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58bd36c2da934c91b443ce6f5b4f2fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea7ee0cb82546f2abd79428182fea1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Separation score: 0.4837\n",
      "Average distance between similar pairs: 0.7386\n",
      "Average distance between non-similar pairs: 0.7060\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a63ceb68d74e416db2a8229de2d39070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "Separation score: 0.4842\n",
      "Average distance between similar pairs: 0.7407\n",
      "Average distance between non-similar pairs: 0.7090\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "513175fb71c24e1ea13322fa76b04f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2\n",
      "Separation score: 0.4856\n",
      "Average distance between similar pairs: 0.7409\n",
      "Average distance between non-similar pairs: 0.7120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "270da13be87342ba95a48545797dbe43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 3\n",
      "Separation score: 0.4871\n",
      "Average distance between similar pairs: 0.7411\n",
      "Average distance between non-similar pairs: 0.7152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcbc6a4de66242ee87495962ce7a0f1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4\n",
      "Separation score: 0.4883\n",
      "Average distance between similar pairs: 0.7423\n",
      "Average distance between non-similar pairs: 0.7190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f241a1b8d3a64086b582579834b5a50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 5\n",
      "Separation score: 0.4889\n",
      "Average distance between similar pairs: 0.7439\n",
      "Average distance between non-similar pairs: 0.7216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f6f9bfb192f445ebbd19e5bb19c147e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6\n",
      "Separation score: 0.4894\n",
      "Average distance between similar pairs: 0.7457\n",
      "Average distance between non-similar pairs: 0.7246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08787fa79f0c4c818d470102a7828891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 7\n",
      "Separation score: 0.4903\n",
      "Average distance between similar pairs: 0.7468\n",
      "Average distance between non-similar pairs: 0.7273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5103cd2464f5481b8ed9b19aba1edf6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8\n",
      "Separation score: 0.4917\n",
      "Average distance between similar pairs: 0.7462\n",
      "Average distance between non-similar pairs: 0.7296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7648a04cfa4f4887af2b28d06f080c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 9\n",
      "Separation score: 0.4928\n",
      "Average distance between similar pairs: 0.7466\n",
      "Average distance between non-similar pairs: 0.7322\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c4d4f62abf141b9ada0e4bcccd96f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10\n",
      "Separation score: 0.4941\n",
      "Average distance between similar pairs: 0.7464\n",
      "Average distance between non-similar pairs: 0.7345\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "972d0e5f287649e29c490e77558832a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 11\n",
      "Separation score: 0.4951\n",
      "Average distance between similar pairs: 0.7459\n",
      "Average distance between non-similar pairs: 0.7362\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dbcaae03e2f42e4af05ebdd13784e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 12\n",
      "Separation score: 0.4957\n",
      "Average distance between similar pairs: 0.7461\n",
      "Average distance between non-similar pairs: 0.7374\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef4253844e1464ebe582bd9685b5e1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 13\n",
      "Separation score: 0.4962\n",
      "Average distance between similar pairs: 0.7459\n",
      "Average distance between non-similar pairs: 0.7383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6d4804a71b84aff96e2661441547a22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 14\n",
      "Separation score: 0.4964\n",
      "Average distance between similar pairs: 0.7459\n",
      "Average distance between non-similar pairs: 0.7387\n"
     ]
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=num_epochs, warmup_steps=warmup_steps, optimizer_params={'lr': 1e-4},\n",
    "          evaluator=evaluator, evaluation_steps=len(train_dataloader))\n",
    "\n",
    "# model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=50, warmup_steps=10, optimizer_params={'lr': 5e-5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32563233"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_1 = model.encode(questions[0], normalize_embeddings=True)\n",
    "embeddings_2 = model.encode(generated_questions[0]['question'], normalize_embeddings=True)\n",
    "\n",
    "# compute cosine similarity as dot product of normalized embeddings\n",
    "import numpy as np\n",
    "np.dot(embeddings_1, embeddings_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model.save_pretrained('../finetuned_models/embeddings_finetune_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Test fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import PeftModel\n",
    "\n",
    "new_model = SentenceTransformer(model_id)\n",
    "\n",
    "new_encoder_model = list(new_model[0].children())[0]\n",
    "new_encoder_model = PeftModel.from_pretrained(model_id='../finetuned_models/embeddings_finetune_model', model=new_encoder_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32563233"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_1 = new_model.encode(questions[0], normalize_embeddings=True)\n",
    "embeddings_2 = new_model.encode(generated_questions[0]['question'], normalize_embeddings=True)\n",
    "\n",
    "# compute cosine similarity as dot product of normalized embeddings\n",
    "import numpy as np\n",
    "np.dot(embeddings_1, embeddings_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "synthlume",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
